from bs4 import BeautifulSoup
import csv
import urllib2

#Open's input csv file and appends the file names to the fileNames array.
fileNames = []
with open("test.csv", "rb") as f:
	reader = csv.reader(f)
	next(reader)
	for row in reader:
		fileNames.append(row[0])
	f.close()	

print fileNames
searchUrl = "https://searchg.symantec.com/search?q="
searchUrlEnd = "&x=17&y=20&charset=utf-8&client=symc_en_US&context=ent&hitsceil=100&output=xml_no_dtd&proxystylesheet=symc_en_US&x=0&y=0&ulang=en&sort=date%3AD%3AL%3Ad1&entqr=0&entqrm=0&entsp=a&wc=200&wc_mc=1&oe=UTF-8&ie=UTF-8&ud=1&site=symc_en_US"

csvRows = []

#For each file name in fileNames, Symantec Database is searched and a type of malware is identified.
for name in fileNames:
	url = searchUrl
	url += name
	url += searchUrlEnd
	page = urllib2.urlopen(url)
	soup = BeautifulSoup(page.read())
	if soup.find(attrs={"onclick" : "TrackResult(this, 1)"}) != None:
		inputTag = soup.find(attrs={"onclick" : "TrackResult(this, 1)"})
		typeUrl = (inputTag.get('href'))
		typePage = urllib2.urlopen(typeUrl)
		typeSoup = BeautifulSoup(typePage.read())
		malwareType = typeSoup.find(string="Type: ").next_element.next_element.next_element.string
		row = [name,malwareType,typeUrl]
		csvRows.append(row)

	else:
		row = [name,"NA","NA"]
		csvRows.append(row)

with open("output.csv", "w+") as o:
	writer = csv.writer(o)
	writer.writerows(csvRows)
